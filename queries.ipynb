{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "\n",
    "## Queries using inverted indexes\n",
    "\n",
    "------\n",
    "\n",
    "* 152037\n",
    "* 151685\n",
    "* 151564\n",
    "\n",
    "------\n",
    "\n",
    "For this algorithm we used Python since it’s a scripting language and already has built in\n",
    "functions as to split lines, open files, etc. easily, also we used an iPython Jupyter Notebook\n",
    "since it makes the whole ordeal easier to debug and when running it you can see the functions\n",
    "alongside their results, making the code clearer.\n",
    "\n",
    "------\n",
    "\n",
    "Install at [Jupyter](http://jupyter.org/install) or run it remotely at [My Binder](https://hub.mybinder.org/user/xyxxyyxy-information_retrieval-gbnflbwk/notebooks/queries.ipynb\n",
    ")\n",
    "\n",
    "------\n",
    "Sample files created by using the text in this document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intersects {'test4.txt'}\n",
      "user {'test4.txt'}\n",
      "prints {'test4.txt'}\n",
      "exists {'test4.txt'}\n",
      "until {'test4.txt'}\n",
      "more {'test4.txt'}\n",
      "no {'test4.txt'}\n",
      "all {'test4.txt'}\n",
      "pass {'test4.txt'}\n",
      "recursive {'test4.txt'}\n",
      "place {'test4.txt'}\n",
      "pool {'test4.txt'}\n",
      "individually {'test4.txt'}\n",
      "syntax {'test4.txt'}\n",
      "evaluate {'test4.txt'}\n",
      "where {'test4.txt'}\n",
      "terms {'test4.txt'}\n",
      "then {'test4.txt'}\n",
      "respectively, {'test4.txt'}\n",
      "understand, {'test4.txt'}\n",
      "meaning {'test4.txt'}\n",
      "operators {'test4.txt'}\n",
      "not {'test4.txt'}\n",
      "which {'test4.txt'}\n",
      "each {'test4.txt'}\n",
      "into {'test4.txt'}\n",
      "human {'test4.txt'}\n",
      "on {'test4.txt'}\n",
      "based {'test4.txt'}\n",
      "could {'test4.txt'}\n",
      "something {'test4.txt'}\n",
      "decide {'test4.txt'}\n",
      "readable {'test4.txt'}\n",
      "earlier {'test3.txt'}\n",
      "than {'test4.txt'}\n",
      "system {'test4.txt'}\n",
      "results {'test3.txt', 'test4.txt'}\n",
      "consisting {'test3.txt'}\n",
      "both {'test3.txt'}\n",
      "intersect {'test3.txt'}\n",
      "later {'test3.txt'}\n",
      "between {'test3.txt'}\n",
      "mix {'test3.txt'}\n",
      "on, {'test3.txt'}\n",
      "will {'test3.txt'}\n",
      "implemented {'test3.txt'}\n",
      "use {'test3.txt'}\n",
      "intersections, {'test3.txt'}\n",
      "next, {'test3.txt'}\n",
      "sets {'test3.txt', 'test4.txt'}\n",
      "and {'test1.txt', 'test0.txt', 'test2.txt', 'test4.txt'}\n",
      "handled {'test2.txt'}\n",
      "language {'test0.txt'}\n",
      "have {'test1.txt'}\n",
      "a {'test3.txt', 'test1.txt', 'test0.txt', 'test2.txt', 'test4.txt'}\n",
      "index, {'test1.txt'}\n",
      "since {'test0.txt'}\n",
      "inverted {'test1.txt'}\n",
      "python {'test0.txt'}\n",
      "used {'test1.txt', 'test0.txt'}\n",
      "being {'test1.txt'}\n",
      "we {'test3.txt', 'test1.txt', 'test0.txt', 'test2.txt', 'test4.txt'}\n",
      "create {'test2.txt'}\n",
      "this {'test1.txt', 'test0.txt', 'test4.txt'}\n",
      "added {'test1.txt'}\n",
      "done {'test1.txt'}\n",
      "once {'test1.txt'}\n",
      "queries, {'test2.txt'}\n",
      "word {'test1.txt', 'test2.txt'}\n",
      "any {'test1.txt'}\n",
      "what {'test2.txt'}\n",
      "files {'test1.txt'}\n",
      "there {'test1.txt'}\n",
      "how {'test2.txt'}\n",
      "knew {'test1.txt'}\n",
      "contains {'test1.txt'}\n",
      "words {'test1.txt'}\n",
      "function {'test3.txt', 'test2.txt', 'test4.txt'}\n",
      "scripting {'test0.txt'}\n",
      "within {'test1.txt'}\n",
      "forementioned {'test1.txt'}\n",
      "it’s {'test0.txt'}\n",
      "with {'test1.txt'}\n",
      "was {'test2.txt', 'test4.txt'}\n",
      "these {'test1.txt', 'test4.txt'}\n",
      "for {'test3.txt', 'test1.txt', 'test0.txt', 'test4.txt'}\n",
      "when {'test0.txt'}\n",
      "our {'test1.txt', 'test4.txt'}\n",
      "ordeal {'test0.txt'}\n",
      "index {'test1.txt'}\n",
      "code {'test0.txt'}\n",
      "is, {'test1.txt'}\n",
      "are {'test1.txt'}\n",
      "duplicates {'test1.txt'}\n",
      "of {'test3.txt', 'test1.txt', 'test2.txt', 'test4.txt'}\n",
      "created {'test1.txt', 'test4.txt'}\n",
      "couldn’t {'test1.txt'}\n",
      "be {'test1.txt'}\n",
      "issue {'test2.txt'}\n",
      "making {'test0.txt'}\n",
      "handle {'test3.txt', 'test1.txt'}\n",
      "that {'test1.txt', 'test2.txt', 'test4.txt'}\n",
      "order {'test1.txt'}\n",
      "so {'test2.txt'}\n",
      "did {'test1.txt', 'test2.txt'}\n",
      "as {'test1.txt', 'test0.txt'}\n",
      "nested {'test1.txt'}\n",
      "sets, {'test1.txt'}\n",
      "you {'test0.txt'}\n",
      "ready {'test1.txt'}\n",
      "in, {'test1.txt'}\n",
      "their {'test0.txt'}\n",
      "it's {'test1.txt'}\n",
      "clearer {'test0.txt'}\n",
      "contained {'test1.txt', 'test2.txt'}\n",
      "results, {'test0.txt'}\n",
      "adding {'test1.txt'}\n",
      "alongside {'test0.txt'}\n",
      "convert {'test4.txt'}\n",
      "see {'test0.txt'}\n",
      "final {'test4.txt'}\n",
      "can {'test0.txt', 'test4.txt'}\n",
      "list {'test1.txt', 'test2.txt'}\n",
      "first {'test1.txt'}\n",
      "big {'test2.txt'}\n",
      "debug {'test0.txt'}\n",
      "easier {'test0.txt'}\n",
      "step {'test4.txt'}\n",
      "next {'test2.txt'}\n",
      "whole {'test0.txt'}\n",
      "the {'test3.txt', 'test1.txt', 'test0.txt', 'test2.txt', 'test4.txt'}\n",
      "opposite {'test2.txt'}\n",
      "it {'test3.txt', 'test0.txt', 'test4.txt'}\n",
      "notebook {'test0.txt'}\n",
      "running {'test0.txt'}\n",
      "ipython {'test0.txt'}\n",
      "easily, {'test0.txt'}\n",
      "structure {'test1.txt'}\n",
      "split {'test0.txt', 'test2.txt'}\n",
      "yields {'test2.txt'}\n",
      "algorithm {'test0.txt'}\n",
      "files, {'test0.txt'}\n",
      "one {'test2.txt', 'test4.txt'}\n",
      "inverse_search {'test2.txt'}\n",
      "makes {'test0.txt'}\n",
      "jupyter {'test0.txt'}\n",
      "an {'test0.txt', 'test2.txt'}\n",
      "structures, {'test1.txt'}\n",
      "also {'test0.txt'}\n",
      "etc {'test0.txt'}\n",
      "single {'test2.txt'}\n",
      "open {'test0.txt'}\n",
      "lines, {'test0.txt'}\n",
      "built {'test0.txt'}\n",
      "search {'test2.txt', 'test4.txt'}\n",
      "or {'test2.txt'}\n",
      "to {'test3.txt', 'test1.txt', 'test0.txt', 'test2.txt', 'test4.txt'}\n",
      "query {'test2.txt', 'test4.txt'}\n",
      "functions {'test3.txt', 'test0.txt'}\n",
      "is {'test2.txt'}\n",
      "in {'test1.txt', 'test0.txt', 'test2.txt', 'test4.txt'}\n",
      "documents {'test2.txt'}\n",
      "has {'test0.txt'}\n",
      "already {'test0.txt'}\n"
     ]
    }
   ],
   "source": [
    "# add the files to the same folder as the one running this notebook and name them in the following\n",
    "# manner: \"test1.txt\", \"test2.txt\", etc and modify the init() function accordingly in line 12\n",
    "class token:\n",
    "    def __init__(self):\n",
    "        self.files = set()\n",
    "        self.word = \"\"\n",
    "        \n",
    "files = set()\n",
    "words = set()\n",
    "\n",
    "def init():\n",
    "    for i in range (0, 5):\n",
    "        file = \"test%r.txt\" %i\n",
    "        files.add(file)\n",
    "        open(file)\n",
    "        for line in open(file):\n",
    "            tmp = line.lower().replace(\"?\",\"\").replace(\".\",\"\").split()\n",
    "            for j in tmp:\n",
    "                flag = False\n",
    "                w = token()\n",
    "                w.word = j\n",
    "                w.files.add(file)\n",
    "                for t in words:\n",
    "                    if t.word == j:\n",
    "                        t.files.add(file)\n",
    "                        flag = True\n",
    "                if flag == False:\n",
    "                    words.add(w)\n",
    "    for t in words:\n",
    "        print(t.word, t.files)\n",
    "        \n",
    "init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we created a structure that contains the word and the files it's contained in, we did this is, in order\n",
    "to handle the index as a list of these structures, with the forementioned nested list within. For adding the words we used sets, as we knew that there couldn’t be any duplicates. Once the words are done\n",
    "being added we have our inverted index, ready to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test3.txt', 'test2.txt', 'test4.txt'}\n",
      "{'test2.txt'}\n",
      "{'test3.txt', 'test1.txt', 'test2.txt', 'test4.txt'}\n",
      "{'test3.txt', 'test1.txt', 'test0.txt'}\n"
     ]
    }
   ],
   "source": [
    "def search(term):\n",
    "    for i in words:\n",
    "        if i.word == term:\n",
    "            return i.files\n",
    "        \n",
    "def inverse_search(term):\n",
    "    for i in words:\n",
    "        if i.word == term:\n",
    "            return files ^ i.files\n",
    "\n",
    "def intersection(term1, term2):\n",
    "        return term1.intersection(term2)\n",
    "            \n",
    "print(intersection(search(\"we\"), search(\"function\")))\n",
    "print(intersection(search(\"search\"), search(\"or\")))\n",
    "\n",
    "print(inverse_search(\"built\"))\n",
    "print(intersection(inverse_search(\"search\"), inverse_search(\"or\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next big issue was how to split the queries, so what we did was create a `search()` function\n",
    "and an `\n",
    "inverse_search()` function that handled one word queries, that is a query that yields the\n",
    "list of documents a single word is contained in or the opposite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we implemented a function to handle intersections, for we will use it later on, to intersect\n",
    "between sets consisting of the results of a mix of both earlier functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'test3.txt', 'test2.txt', 'test4.txt'}]\n",
      "[{'test3.txt', 'test1.txt', 'test0.txt'}]\n",
      "[{'test3.txt', 'test1.txt', 'test0.txt'}]\n",
      "[{'test3.txt'}]\n",
      "[{'test1.txt', 'test0.txt'}]\n"
     ]
    }
   ],
   "source": [
    "def ask(sentence):\n",
    "    tmp = sentence.lower().replace(\" \",\"\").split(\"&\")\n",
    "    queries = []\n",
    "    for i in tmp:\n",
    "        if \"!\" in i:\n",
    "            queries.append(inverse_search(i.replace(\"!\",\"\")))\n",
    "        else:\n",
    "            queries.append(search(i))\n",
    "    query(queries)\n",
    "\n",
    "def query(x):\n",
    "    better_queries = []\n",
    "    if len(x)%2:\n",
    "        j = 0\n",
    "        while j < len(x) - 1:\n",
    "            better_queries.append(intersection (x[j], x[j+1]))\n",
    "            j += 2\n",
    "        better_queries.append(x[j])\n",
    "    else:\n",
    "        j = 0\n",
    "        while j < len(x):\n",
    "            better_queries.append(intersection (x[j], x[j+1]))\n",
    "            j += 2\n",
    "    \n",
    "    if len(better_queries) != 1:\n",
    "        query(better_queries)\n",
    "    else:\n",
    "        if better_queries[0] == set():\n",
    "            print(\"none\")\n",
    "        else:\n",
    "            print (better_queries)\n",
    "                \n",
    "\n",
    "ask(\"we & function\")\n",
    "ask(\"!search & !or\")\n",
    "ask(\"!search & !or & we\")\n",
    "ask(\"!search & !or & we & function\")\n",
    "ask(\"!search & !or & we & !function\")\n",
    "# try it for yourself\n",
    "# use syntax such as \"something & somethingElse & anotherSomethingElse\", \" something & !somethingElse\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step was to convert a human readable search into a query our system could\n",
    "understand, for this we created a syntax where we can decide to search for something based\n",
    "on the operators `&` and `?` meaning `and` and `not` respectively, we then evaluate each of\n",
    "these terms individually and place the results in a pool which we pass to a recursive\n",
    "function that intersects all of these results until no more sets than one exists and prints it for the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
